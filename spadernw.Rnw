\documentclass{article}
\usepackage{Sweave}
\usepackage{geometry}
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{amsmath,amssymb}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{float,endfloat}
\usepackage{appendix}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\DeclareMathOperator*{\argmin}{argmin}

\title{Stock assessment using the\\ McKendrick-Gurtin-MacCamy-Murphy\\ partial differential equation}

\author{
  Alexander Campbell\\
  Queensland Department of Agriculture and Fisheries\\
  Brisbane, Australia
  \and
  Oscar Angulo\\
  Departamento de Matem\'{a}tica Aplicada\\
  Universidad de Valladolid\\
  Valladolid, Spain
  \and
  Tomislav Buric\\
  Faculty of Electrical Engineering and Computing,\\
  University of Zagreb, Croatia
}

\begin{document}
\maketitle

\begin{abstract}
In 1926 Anderson McKendrick introduced a differential equation that describes a mortality process for an age-structured population.  Morton Gurtin and Richard MacCamy (1974), and then Lea Murphy (1983), made key extensions such that, with the addition of a time-dependent mortality term, the equation encapsulates much of the core of modern stock assessment.  We introduce numerical and analytical techniques that enable efficient parameter estimation for fishery models built using this class of equations and demonstrate these using an Australian barramundi (\emph{Lates calcarifer}) fishery.  We highlight the additional insight the differential formalism provides on questions of scale and parameter identifiability, and discuss the characterisation of uncertainty.
\end{abstract}

\section{Introduction}
One of the ways to see the great power of calculus is through its ability to linearise.  Variables which become inextrcably intertwined on large time scales often operate independently when considered infinitesimally, and thus can be specified in a simple additive fashion. 

Providing there is sufficient information available to calibrate them, population models that explicitly represent the size\footnote{Here we are using `size' as a shorthand for any physiologically important dimension, for example age, length, weight, body mass etc.  A general term for these models is physiologically structured population models \citep{Metz2014}.} of the individual are significantly more realistic than those that lump this dimension into one or a few state variables.  This enhanced realism is particularly important for populations which experience a forcing, or can be controlled through a behaviour, that acts along the dimension - for example a time-dependent mortality process that varies as a function of size, or a size-based management control.   

Here we present a size structured population model wherein the population is subject to a time-dependent mortality effect, namely fishing, and for which parameters are estimated by minimising the discrepancy between predictions of the model and data.  This is also the goal of the applied science of `stock assessment' \citep{Hilborn1992}, where the estimated parameters are used to guide the management of a fishery.  The methods we present here, however, differ somewhat from those used in stock assessment, and bear more resemblance to the mathematical ecology literature.  We represent the physiological dimension mathematically as a continuum, rather than as a discrete set of states as is done almost exclusively in stock assessment.\footnote{The only exception we are aware of is \cite{Dueri2012a,Dueri2012b}, about which more later.}  The decision to represent both time and size as a continuum means that we are dealing with partial differential equations, and brings with it some challenges as well as some advantages.  The aim of this paper is to show one of way of tackling the challenges and to highlight some of the advantages.  While some things are ostensibly harder in this paradigm, such as the need to solve differential equations using numerical techniques, some things are possible that are not in the discrete paradigm, and some things actually become easier.  Perhaps the main advantage though is conceptual clarity and access to powerful theoretical tools.

In section \ref{sec:m2m} we give some context to the Murphy equation by showing how it has evolved from earlier theories.  A fishery model based on this framework is introduced in section \ref{sec:fm}, and a numerical scheme for its numerical solution is given in section \ref{sec:ns}.  Until this point nothing is particularly original.  The main technical contributions of the paper come in section \ref{sec:pe} where we introduce numerical and analytic techniques for efficient parameter estimation.  In section \ref{sec:sui} we explore the three interrelated concepts of identifiability, uncertainty and scale.  The approach is demonstrated in section \ref{sec:app} where we fit the model to data from a barramundi fishery in Queensland, Australia.  We close with a discussion in section \ref{sec:disc}.

\section{From Malthus to Murphy}\label{sec:m2m}
The simplest population model follows the Malthusian principle 
\begin{equation}
\dot{N} = \alpha N,
\end{equation}
which implies exponential growth and is clearly inappropriate for real world populations that must compete for resources.  \citet{Verhulst1845,Verhulst1847} understood that the growth rate should depend on total population size and achieved this in the simplest possible way,
\begin{equation}
\dot{N} = (\alpha_0-\beta_0 N)N
\end{equation}
so that the rate of increase decreases as the population grows, and can be negative for large $N$. This model can be solved exactly,
\begin{equation}
N(t) = \frac{ \zeta}{1 + \left( \frac{\zeta}{N(0)}-1\right)e^{-\alpha_0 t}}
\end{equation}
describing the evolution of a population towards the stable equilibrium point $\zeta=\alpha_0/\beta_0$.

A limitation of the Verhulstian model is that it does not consider the age of the population.  The first explicit reference to age in a differential equation was made by \citet{McKendrick1926}\footnote{\citet{Lotka1925} clearly understood the concept and many of the consequences but did not write down the equation from which they flow. In ecology it is often referred to as the \citet{vonFoerster1959} equation after he developed the ideas apparently without being aware of \citet{McKendrick1926}.}, 
\begin{equation}
\frac{\partial n(a,t)}{\partial t} + \frac{\partial n(a,t)}{\partial a} = -\mu(a,t) n(a,t)
\end{equation}
where $n(a,t)$ is the density of individuals of age $a$ at time $t$ ( $\int_{a_1}^{a_2}n(a,t)\,da$ gives the total number of individuals aged between $a_1$ and $a_2$ at time $t$), and $\mu$ is rate at which they die per unit of population. 

This equation requires a boundary condition on $n(a,t)$ in both $t$ and $a$. The initial condition,
\begin{equation}
n(a,0) = f(a)
\end{equation}
says that the initial age distribution of the population is $f(a)$.  The other boundary condition is the birth rate, also known as the renewal equation, 
\begin{equation}
n(0,t) = \int_a b(a)n(a,t)\,da
\end{equation}
where $b(a)$ is the birth rate at age $a$.  This is an unusual boundary condition for a PDE in that it is dynamically computed from the population at time t.

However the McKendrick model has the same limitation as the Malthusian one - the mortality process is not dependent on the size of the population.  Clearly a Verhulstian effect is needed.  Furthermore, age is often less appropriate than other physiological attributes \citep{Frank1960}. \citet{Sinko1967} give a rigorous derivation of an age \emph{and} size structured McKendrick PDE, and show how the mortality component of the equation is connected to Verhulst's model, however they do not prove existence and uniqueness\footnote{A reference is made to a proof of existence which could not be located.}, nor show the full connection between McKendrick PDEs and Verhulstian models.  This was not achieved until \citet{Gurtin1974} proved existence and uniqueness of solutions to equations of the form
\begin{equation}
  \begin{split}
    \frac{\partial \rho(a,t)}{\partial t} + \frac{\partial n(a,t)}{\partial a} &= -\mu\left(a,\int_a n(a,t)dz\right) n(a,t)\\
    n(0,t) &= \int_a b(a)n(a,t)\,da\\
%    &N(t) = \int_a n(a,t)\,da
  \end{split}
\end{equation}
where the mortality term now is dependent on the size of the population. A simple model of this form, introduced in \citet{Gurtin1978}, has
\begin{equation}
  \begin{split}
    \mu(a,N,t) &= \mu_0 + \mu_1 N\\
    b(a) &= b_0 e^{-b_1 a}
  \end{split}
\end{equation}
which they showed reduces to Verhulst's model (with $\alpha_0 \equiv b_0 - b_1 - \mu_0$ and $\beta_0 \equiv \mu_1$) in the special case of a population that has an initial age distribution which is balanced in a certain sense. Away from this balance the initial birth rate is either `small' relative to the initial population, and the population initially decreases; alternatively it is `large', and the population surges to a Memaximum which is larger than its ultimate equilibrium value. 

\citet{vanSickle1977} analysed a linear (no density dependence) size-structured McKendrick PDE in the context of a fishery model and made the deep observation that a bump may exist in the size-frequency distribution at equilibrium due to fish growing into those size classes faster than they die or grow out of them, but it was \citet{Murphy1983} who built on density dependence and size were incorporated in the McKendrick PDE framework, and the Mprhpy trick ..  \citet{Murphy1983}'s model is
\begin{equation}
  \begin{split}
    \frac{\partial n(x,t)}{\partial t} + \frac{\partial g(x)n(x,t)}{\partial x} &= -\mu\left(x,\int_x n(x,t)dx\right) n(x,t)\\
    g(0)n(0,t) &= \int_x b(x)n(x,t)\,dx\\
%    &N(t) = \,dx
  \end{split}
\end{equation}
where $x$ is size and $g(x)$ is the growth function. \citet{vanSickle1977} gives an intuitive derivation for the $g(0)$ term in the birth subequation. %Existence and uniqueness for the Murhpy model was finally proved by ?

%Pre-dating \citet{Gurtin1974},  
%and they do not provide existence and uniqueness. We will call models of length and age structure the Sinko-Streier type.

%Interestingly \footnote{\citet{Sinko1967}  but their formulation lacks the critical $N$ term in the death function - density dependence is not taken into account}  age and then setting $\mu$ to .. but they do not actually write down the PDE with population dependence inside it, nor do they seem to realise such a model is a different class from \ref{eq:1} and that the existence and uniqueness proof given in \citet{Sinko1968}.

\section{Fishery models}\label{sec:fm}
Once we introduce a time-dependent mortality function we have all the ingredients for a simple size-structured fishery model,\footnote{Consistent with the fishery literature we will use $z$ for the mortality process.}
\begin{subequations}
\label{eq:1}
\begin{align}
\frac{\partial n(x,t)}{\partial t} + \frac{\partial [g(x)n(x,t)]}{\partial x} &=
-z(x,N(t),t)n(x,t) \label{eq:1.1}\\
g(0)n(0,t) &=  \int_0^{\omega} b(x) n(x,t)\,dx\label{eq:1.2}\\ 
N(t) &= \int_0^{\omega} n(x,t)\, dx
\end{align}
\end{subequations}
where $x$ is the size of the individual, $\omega$ is the Memaximum size, and $b$, $g$ and $z$ represent the processes of birth, growth and death respectively. The birth and growth processes can be parameterised to taste, however in the sequel we will emphasise the importance of analytically tractable parameterisations.  Growth is the simplest in this regard as it will turn out that the \citet{vonBertalanffy1938} form,
\begin{equation}
  g(x) = \kappa (\omega - x)\label{eq:growth}
\end{equation}
is indeed tractable.\footnote{at least in the context of the other choices - they are interrelated.}  A tractable birth rate which is at least biologically plausible for many species is
%\begin{subequations}
%  \begin{align}
\begin{equation}
  b(x) = \left(\alpha_1 x + \alpha_2 x^2\right)\label{eq:birth}.
\end{equation}
  %  \end{align}
%\end{subequations}

The mortality process is given by 
\begin{equation}
  z(x,U(t),t) = \beta + \gamma U(t) + s(x)f(t)\label{seq:2a},
\end{equation}
where $\beta$ and $\gamma$ are, respectively, density-independent and density-dependent natural mortalities, $s(x)$ is the `selectivity' function (different sized fish are differentially selected by the fishing gear), given by
\begin{equation}
  s(x) = \exp(-(x-s_1)^2 / s_2)
\end{equation}
and $f(t)$ is fishing mortality, 
\begin{equation}
  f(t) = \iota e(t)  
\end{equation}
where $\iota$ is the catchability and $e(t)$ is the fishing effort.  The fishing process produces a catch,
\begin{equation}
  c(x,t) = w(x)s(x)f(t)u(x,t)
\end{equation}
where $w(x)$ is the weight of a fish of size $x$, given by
\begin{equation}
  w(x)=w_1 x^{w_2}.
\end{equation}
This completes the specification of a simple fishery system.  The biological component of this system is a slight variant of that analysed by \citet{Murphy1983} - simpler in that growth and births are not density dependent, but more complex in that growth is size-dependent.  Another way to think of it is as the simplest modification of the first model in \citet{Gurtin1978} needed to handle size-dependent growth.  

\citet{Dueri2012a} developed a McKendrick style fishery model for tuna in the Indian Ocean which also includes three spatial dimensions. 

The extent to which this is a non-standard fishery model is discussed further in section \ref{sec:disc}.

It will turn out to be useful to reparameterise the birth function thus
\begin{equation}
  b(x) = \alpha(a_1 x+a_2 x^2).
\end{equation}

%\clearpage
\section{Numerical solutions}\label{sec:ns}
Equation \ref{eq:1} is a nonlinear hyperbolic partial differential equation with a non-local term and a nonlinear and non-local boundary condition.  Even without time-dependence (that is, even considering autonomous biological models of the Murphy type) no analytical solutions are known.  With it, a numerical approach is obviously required.  Significant research has been done in this area, for pointers into the literature see \citet{Angulo2004} and \citet{Angulo2014}.  In this section we follow closely the scheme developed in \citet{Angulo2014}.

We start by reducing the PDE to a set of coupled ODEs by integrating along the characteristic curves \citep{Courant1966}.\footnote{this is analogous to following the mortality process of a particular cohort}  Next, define
\begin{equation}
  z^*(x,U,t)=z(x,U,t)+g_x(x)
\end{equation}
so that \ref{eq:1.1} has the form
\begin{equation}\label{eq:2}
  u_t(x,t) + g(x)u_x(x,t) = -z^*(x,U,t)u(x,t).
\end{equation}
Now denote by $x(t;t^*,x^*)$ the characteristic curve of Equation \ref{eq:2} that takes the value $x^*$ at time $t^*$, which is the solution to the following initial value problem
\begin{equation}\label{eq:2.2}
  \begin{cases}
    \frac{d}{dt} x(t;t^*,x^*)=g(x(t;t^*,x^*)), & t\geq t^*\\
    x(t^*;t^*,x^*)=x^* &. 
  \end{cases}
\end{equation}
Next, define the function
\begin{equation}
  r(t;t^*,x^*)=u(x(t;t^*,x^*),t)
\end{equation}
which satisfies the following initial value problem
\begin{equation}
  \begin{cases}
    \frac{d}{dt} r(t;t^*,x^*)=-z^*(x(t;t^*,x^*),U,t)r(t;t^*,x^*), & t\geq t^*,\\
    r(t^*;t^*,x^*) = u(x^*,t^*), &
  \end{cases}
\end{equation}
and therefore can be represented by 
\begin{equation}\label{eq:2.5}
  r(t;t^*,x^*)=u(x^*,t^*)\exp\left(-\int_{t^*}^{t}z^*(x(\tau;t^*,x^*),U,t)\,d\tau\right).
\end{equation}
The coupled problems \ref{eq:2.2} and \ref{eq:2.5} are then simultaneously integrated together with boundary condition \ref{eq:1.2}. 

\citep{Angulo2014} developed a second order numerical scheme, given in Algorithm \ref{alg:original}.

%As with all Mckendrick style PDEs it can be reduced to a coupled ODE problem by integrating along the characteristic curves \citep{Kot2001}. 

\begin{algorithm}
  \caption{Numerical scheme for }\label{alg:original}
  \begin{algorithmic}
    \State $X_0^{n+1} \gets 0$
    \State $X_{j+1}^{n+1} \gets X_j^n + k g(X_{j+1}^{n+1/2}), 0 \leq j \leq J$
    \State $U_{j+1}^{n+1} \gets U_j^n \exp\left(-k z^*(X_{j+1}^{n+1/2},\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}),t^{n+1/2})\right), 0 \leq j \leq J$
    \State $U_0^{n+1} \gets \mathcal{Q}(\mathbf{X}^{n+1},b(\mathbf{U}^{n+1})) / g(X_{0}^{n+1})$
    \State $X_0^{n+1/2} \gets 0$
    \State $X_{j+1}^{n+1/2} \gets X_j^n + (k/2) g(X_j^n), 0 \leq j \leq J$
    \State $U_{j+1}^{n+1/2} \gets U_j^n \exp\left(-(k/2) z^*(X_j^n,\mathcal{Q}(\mathbf{X}^n,\mathbf{U}^n),t^n)\right), 0 \leq j \leq J$
    \State $U_0^{n+1/2} \gets \mathcal{Q}(\mathbf{X}^{n+1/2},b(\mathbf{U}^{n+1/2})) / g(X_{0}^{n+1/2})$
  \end{algorithmic}
\end{algorithm}

Following \citet{Angulo2014} we use an adaptive mesh that keeps the number of nodes along the size dimension constant as the algorithm steps forward: at time $t^{n+1}$ we remove the grid node $X_l^{n+1}$ that satisfies
\begin{equation}
  |X_{l+1}^{n+1} - X_{l-1}^{n+1}| = \text{min}_{1\leq j\leq J+1} |X_{j+1}^{n+1} - X_{j-1}^{n+1}|
\end{equation}
See \citet{Angulo2014} for convergence analysis and numerical experiments. 

%\clearpage
\section{Parameter Estimation}\label{sec:pe}
Originality in the nature of the objective function.

Having solved the model, we are in a position to critique its performance.  Clearly the kind of data that is available will determine the kinds of critiques that are possible, but it is instructive to consider the what data would look like in the ideal case and work backwards.  Mathematically, the relevant discipline for this is control theory.  Control theory relates observables (data) to models, and makes statements about under what conditions the observables are sufficient/neccesary for the model states and parameters to be identified.  Given that the state of the system is given by $n(x,t)$, an ideal observation would be precisely that - a space-time continuous sheet.. however this is completely impractical, akin to using the actual geography as your map for the geography, and anyway we have a better candidate.. the effort that is put into 

The model makes a prediction of the size-structured catch, $c(x,t) = s(x) \iota e(t) n(x,t)$, 

If we think about parameter estimation from 

A natural way to calibrate such a model is against fishery catch-at-size data. A little bit of control theory helps to see this. 

Control theory asks what are the inputs to the model and what are the outputs. Is the model observable. 

The model is calibrated against fishery catch-at-size data. This comes from two sources: commercial catch data (a scalar time series representing removals from the population), and scientific monitoring program data on the size structure of the commercial catch. These are combined to produce the `observation', $c(x,t)$: the catch rate (in kilograms per centimetre) at time $t$ and size $x$. It is this observation to which the model is fit:
\begin{equation}
K(\theta) = \int_0^T \int_0^\omega |s(x)w(x)f(t)u(x,t) - c(x,t)| \,dx\,dt
\end{equation}
The gradient of $K$ with respect to $\theta$ is given by
\begin{equation}
\int_0^T \int_0^\omega
\left(s(x)w(x)f_\theta(t)u(x,t)+s(x)w(x)f(t)p(x,t)\right)\times 
\begin{cases}
-1, &  s(x)w(x)f(t)u(x,t) < c(x,t)\\
\phantom{-}1, & s(x)w(x)f(t)u(x,t)>c(x,t) 
\end{cases}\,dx\,dt
\end{equation}

%\begin{equation}
%K(\theta) = \int_0^T \int_0^\omega \big(s(x)w(x)f(t)u(x,t) - c(x,t)\big)^2 \,dx\,dt
%\end{equation}
%The derivative of $K$ with respect to $\theta$ is given by
%\begin{equation}
%\int_0^T \int_0^\omega
%2\big(s(x)w(x)f(t)u(x,t)-c(x,t)\big)\big(s(x)w(x)f_\theta(t)u(x,t)+s(x)w(x)f(t)p(x,t)\big)\,dx\,dt
%\end{equation}
where $p(x,t)=u_\theta(x,t)$ are solutions of the the sensitivity-PDE \citep{Borggaard1997}: %,Stanley2002}.

\begin{equation}
  \frac{d F}{d\theta} = F_\theta + F_u p + F_{u_t} p_t + F_{u_x} p_x = 0
\end{equation}
with
\begin{equation}
  F: \begin{cases}
    u_t + \left[g(x;\theta)u\right]_x + z(x,U,t;\theta)u = 0 &\\
    g(0)u(x,0) = \int_x b(x)u(x,t)\,dx & \end{cases}
\end{equation}
so that the sensitivity PDE is given by
\begin{equation}
  p_t + g_\theta u_x + g p_x + g_x p + {g_x}_\theta u + z p + \left(z_\theta + z_U P\right)u = 0
\end{equation}
where
\begin{equation}
  P=U_\theta= \int_0^\omega p(x,t;\theta)\,dx,
\end{equation}
with boundary condition
\begin{equation}
  g(0;\theta)_\theta u(0,t;\theta) + g(0;\theta) p(0,t;\theta) = \int_0^\omega b_\theta(x;\theta)u(x,t;\theta) + b(x;\theta)p(x,t;\theta) \,dx .
\end{equation}

Substituting in the birth, growth and death functions, sensitivity PDEs for each parameter can be derived. These are contained in Appendix \ref{app:pde}. These PDEs can be reduced to coupled ODE problems along characteristics in a manner analogous to the original PDE case. For all parameters the size ODE (Equation \ref{eq:2.2}) remains unchanged. The integrals for the population ODEs are contained in Appendix \ref{app:sol}.  Following a similar approach to that introduced in the previous section, solutions to the sensitivity PDEs can be found by the numerical schemes given in Appendix \ref{app:num}.  

Look up \citep{Deng2015} and consider \citep{Banks2009}. 

`Infinite-dimensional effects' an issue? \citep{Ackleh2004} Also consider \citet{Picart2011}. 

\subsection{Initial state}
Unfished equilibrium can be derived analytically.

%If we assume that we have a complete fishing history, and that the initial state should therefore be unfished equilibrium, then it is possible to derive the starting condition analytically. 

The general technique is to introduce integral weighting functions to reduce the PDE to coupled ODEs. This was pioneered by \citet{Gurtin1978}, and has since been applied to more complicated models \citep{Murphy1983,Swart1994}. For our model, we start by defining
\begin{equation}
    V(t) = \int_0^{\omega} x u(x,t)\, dx
\end{equation}
and
\begin{equation}
    W(t) = \int_0^{\omega} x^2 u(x,t)\, dx .
\end{equation}
The model PDE (Equation \ref{eq:1}) is then integrated along the size dimension three times, the second and third time having been first multiplied by $x$ and $x^2$ respectively, producing three ODEs.\footnote{This reduction depends on a technical assumption that the initial data $u(x,0)$ has compact support so that $u(x,t)=0$ for sufficiently large $x$. This is obviously biologically realistic.} Eventually we obtain an ODE system (see Appendix \ref{app:eq}) which at equilibrium is given by
%\begin{subequations}
%  \begin{align*}
%    \frac{dU}{dt} &= -(\beta+\gamma U) U + \alpha a_1 V + \alpha a_2 W\\
%    \frac{d V}{d t} &= -(\beta+\gamma U)V + \kappa \omega U - \kappa V\\
%    \frac{d W}{d t} &= -(\beta+\gamma U)W + 2\kappa\omega V - 2\kappa W\\
%  \end{align*}
%\end{subequations}
%so that at equilibrium we have
\begin{subequations}
  \label{eq:eq}
  \begin{align}
  (\beta+\gamma \bar{U}) \bar{U} &= \alpha a_1 \bar{V} + \alpha a_2 \bar{W}\label{seq:eqa}\\
  (\beta + \gamma \bar{U})\bar{V}  &=  \kappa \omega \bar{U} - \kappa \bar{V}\label{seq:eqb}\\
  (\beta+\gamma \bar{U})\bar{W}  &=  2\kappa\omega \bar{V} - 2\kappa \bar{W}\label{seq:eqc}
  \end{align}
\end{subequations}

This can be solved (details in section \ref{sec:solv}), giving
\begin{equation}
  \bar{U} = \frac{1}{\gamma}\bigg(\frac{ \sqrt[3]{9 \alpha a_1 \kappa^2 \omega+18 \alpha a_2 \kappa^2 \omega^2+\kappa\zeta}}{3 \sqrt[3]{\frac23}} +  
  \frac{\sqrt[3]{\frac23}\,\kappa (\alpha a_1  \omega+\kappa)}{\sqrt[3]{9 \alpha a_1 \kappa^2 \omega+18 \alpha a_2 \kappa^2 \omega^2+\kappa\zeta}} - \beta - \kappa\bigg)
\end{equation}  
where
\begin{equation}
\zeta= \sqrt{ 81 \kappa^2 \omega^2 (\alpha a_1 +2 \alpha a_2 \omega)^2 - 12\kappa( \alpha a_1  \omega+ \kappa)^3}.
\end{equation}  

The size structure at equilibrium is then given by
\begin{equation}
  %\begin{split}
  u(x) %&= \frac{g(0)u(0)}{g(x)} \exp\left(- \int_0^x \frac{ z(\lambda,U) } {g(\lambda)}\,d\lambda\right)\\
%  &= \frac{\alpha_1 \bar{V} + \alpha_2 \bar{W}}{\kappa(\omega-x)} \exp\left( -\int_0^x \frac{\beta + \gamma \bar{U}}{\kappa(\omega-\lambda)}\,d\lambda\right)\\
%  &= \frac{\alpha_1 \bar{V} + \alpha_2 \bar{W}}{\kappa(\omega-x)} \exp\left( \left.\frac{(\beta + \gamma\bar{U})\log(\kappa(\omega-\lambda))}{\kappa}\right|_0^x\right)\\
%  &= \frac{\alpha_1 \bar{V} + \alpha_2 \bar{W}}{\kappa(\omega-x)} \exp\left( \kappa^{-1}(\beta + \gamma\bar{U})\log(\kappa(\omega-x)) - \kappa^{-1}(\beta + \gamma\bar{U})\log(\kappa\omega)\right)\\
%  &= \frac{\alpha_1 \bar{V} + \alpha_2 \bar{W}}{\kappa(\omega-x)} \frac{(\kappa(\omega-x))^{\frac{\beta+\gamma\bar{U}}{\kappa}}}{(\kappa\omega)^{\frac{\beta+\gamma\bar{U}}{\kappa}}}\\  
%  &= (\alpha_1 \bar{V} + \alpha_2 \bar{W}) \frac{(\kappa(\omega-x))^{\frac{\beta+\gamma\bar{U}}{\kappa}-1}}{(\kappa\omega)^{\frac{\beta+\gamma\bar{U}}{\kappa}}}\\  
%  &= (\alpha_1 \bar{V} + \alpha_2 \bar{W}) \frac{\kappa^{\frac{\beta+\gamma\bar{U}}{\kappa}-1}(\omega-x)^{\frac{\beta+\gamma\bar{U}}{\kappa}-1}}{\kappa^{\frac{\beta+\gamma\bar{U}}{\kappa}}\omega^{\frac{\beta+\gamma\bar{U}}{\kappa}}}\\  
  = \frac{\left(\alpha a_1 \bar{V} + \alpha a_2 \bar{W}\right) (\omega-x)^{(\beta+\gamma\bar{U})/\kappa-1}}{\kappa \omega^{(\beta+\gamma\bar{U})/\kappa}}
  %\end{split} 
\end{equation}

We also need initial conditions for our sensitivity PDEs. These are, by definition, $d u(x)/d\theta$. The derivations for these are contained in Appendix \ref{app:2}.

For optimisation we use the BFGS \citep{Broyden1970,Fletcher1970,Goldfarb1970,Shanno1970conditioning,Shanno1970optimal} method, with line search due to \citet{more1994line}.

The guiding philosophy is

This has a number of benefits, including

- a small number of parameters to optimise, and therefore the applicability of Quasi-Newton methods, which can be memory intensive. 

\section{Identifiability, Uncertainty and Scale}\label{sec:sui}
The condition number of the Hessian at the global minima is a useful indicator of the identifiability of the model \cite{Thacker1989}. The condition number is the ratio of the largest eigenvalue to the smallest. 
\begin{equation}
  \frac{\partial^2 K}{\partial\theta_i\partial\theta_j} \approx \frac{\psi_i(\theta + \delta_j\epsilon) - \psi_i(\theta-\delta_j \epsilon)}{4\epsilon} + \frac{\psi_j(\theta +\delta_i\epsilon) - \psi_j(\theta - \delta_i\epsilon)}{4\epsilon}
\end{equation}
where
\begin{equation}
  \psi_i(\theta)=\frac{\partial K}{\partial\theta_i}
\end{equation}

Mention the identifiability work with the simplified model. Mention the nice aspect of the hessian approach is that excitablity is taken into account. 

%\begin{equation}
%  \Gamma 
%  \begin{cases}
%    u_t + [g(x)u(x)]_x = \mu(x,U,t) u & \\
%    g(0)u(0) = \int_x b(x)u(x)\,dx &
%  \end{cases}
%\end{equation}   

%\section{Scale, granularity, relationship with optimisation and computational complexity}


\section{Application}\label{sec:app}
Increase threshold.
Quantify uncertainty directly through the hessian - this much change in parameter x .. well, we get the eigenvalues and eigenvectors, they tell us a lot.  From this we can understand the 

Hone in on the best scale... explore as necessary.. 

<<code,echo=FALSE>>=

load(file='spade.RData')

#c.m <- read.table(file='control.model')

J <- 400 #c.m[2,1]
k <- 0.025 #c.m[3,1]

newk <- 1/360

ti <- as.numeric(karumba$Time)
Y <- ceiling(Memax(ti))
N <- Y/k
I <- 2*N

newN <- Y/newk

cek <- k/4

newcat <- array(0,dim=newN+1)
for (i in 1:nrow(karumba)) {
    idx.c <- floor((karumba$Time[i]+newk/2)/newk)
    newcat[idx.c] <- newcat[idx.c] + (karumba$RetainedWholeWeightDerived[i]/newk)/1e3
}

plot((1:(newN+1)-1)*newk,newcat[1:(newN+1)],type='l')

spl <- smooth.spline((1:(newN+1)-1)*newk,newcat[1:(newN+1)],nknots=500,spar=.4)
library(fda)
bspl.basis <- create.bspline.basis(unique(spl$fit$knot))

#outx <- seq(0,1,length=newN+1)
#mut <- array(0,newN+1)
#for (j in 1:(newN+1))
#    mut[j] <- eval.basis(outx[j],bspl.basis) %*% spl$fit$coef
      
#x11(); plot(outx,mut,type='l'

nbasis <- bspl.basis$nbasis
params <- bspl.basis$params
rangeval <- bspl.basis$rangeval
breaks <- c(rangeval[1], params, rangeval[2])
norder <- nbasis - length(breaks) + 2
nbreaks <- length(breaks)
knots<- c(rep(breaks[1], norder -1), breaks, rep(breaks[nbreaks], norder -1))
nbasis <- nbreaks + norder - 2
nk <- length(knots)
splcoef <- spl$fit$coef

sink('karumba-ce-new.dat')
cat(sprintf('%d\n',nk))
for (i in 1:nk)
    cat(sprintf('%f\n',knots[i]))
cat(sprintf('%d\n',nbasis))
for (i in 1:nbasis)
    cat(sprintf('%f\n',splcoef[i]))
sink()


cat <- array(0,dim=N+1)
eff <- array(0,dim=4*N+1)
for (i in 1:nrow(karumba)) {
    idx.e<- floor((karumba$Time[i]+cek/2)/cek)
    idx.c <- floor((karumba$Time[i]+k/2)/k)
    eff[idx.e] <- eff[idx.e] + 1.0/cek
    cat[idx.c] <- cat[idx.c] + (karumba$RetainedWholeWeightDerived[i]/k)/1e3
}

#save(eff,cat,file='cateff.RData')
#load(file='cateff.RData')


Nlf <- nrow(csskc)

ln <- csskc$Length1/10
tl <- csskc$Time

bw <- bw.nrd(ln)
bwt <- bw.nrd(tl)

x <- seq(0,160,length.out=500)
l <- array(0,500)

div <- sum(exp(-((23 - tl)/bwt)^2))

for (j in 1:500)
    for (jj in 1:Nlf)
        l[j] <- l[j] + (1/div)*exp(-((23 - tl[jj])/bwt)^2) * exp( - ((x[j] - ln[jj])/bw)^2 )/Nlf

xt <- seq(0,23,length.out=300)
tt <- array(0,300)
for (j in 1:300)
    for (jj in 1:Nlf)
        tt[j] <- tt[j] + (1/div)*exp(-((xt[j]- tl[jj])/.55)^2)/Nlf





ilv <- array(0,dim=Nlf)
cnt <- array(0,dim=I+1) 

for (i in 1:Nlf) {
    ilv[i] <- N + floor((tl[i]+k/2)/k) 
    cnt[(Y/k + floor((tl[i]+k/2)/k))+1] <- cnt[(Y/k + floor((tl[i]+k/2)/k))+1] + 1
}

Nl <- 0
for (i in 0:I)
    if (cnt[i+1] > min.fish)
        Nl <- Nl+1

lf <- matrix(0,nrow=Nl,ncol=Memax(cnt))
t_id <- array(0,dim=Nl)
t_sz <- array(0,dim=Nl)

kk <- 1
for (i in 0:I) {
    
   if (cnt[i+1] > min.fish) {

       t_id[kk] <- i
       t_sz[kk] <- cnt[i+1]       

       jj <- 1
       for (j in 1:Nlf)
           if (ilv[j]==i) {
               lf[kk,jj] <- ln[j]
               jj <- jj+1
           }
       kk <- kk+1
   }
}

A1 <- 8.588e-5
A2 <- 0.00144

alpha <- .1
beta <- .1
gamma <- 1.1e-7
iota <- 1e-4
kappa <- .1
omega <- 160

phi <- 17
iota1 <- 5.2
iota2 <- 0.619
eta1 <- 1.703205e-8
eta2 <- 2.9526

g <- function(x) { kappa*(omega-x) }
b <- function(x) { alpha*(A1*x + A2*x^2) }
zstar <- function(x,U,t) { beta+gamma*U+s(x)*iota*e(t)-kappa }

w <- function(x) { eta1*x^eta2 }
s <- function(x) { exp(-(x-phi*iota1)^2 / (2*iota2*phi^2)) }

Q <- function(x,V,J) {
  rt <- 0
  for (i in 1:(J-1))
    rt <- rt + (x[i+1]-x[i]) * (V[i]+V[i+1])/2
  rt
}

Q2 <- function(x,u,gv,J) {
  rt <- x[2]*b(x[2])*u[2] - x[1]*b(x[2])*u[2]
  for (i in 2:(J-1))
    rt <- rt + (b(x[i])*u[i]+b(x[i+1])*u[i+1])*(x[i+1]-x[i])
  rt[1] <- rt / (2*gv+x[1]*b(x[1]) - x[2]*b(x[1]))
  return(rt)
}   

e <- function(t) {

  if (t<0)
    {
      return(0)
    }
  else
    {
      cek <- k/2
      idx <- floor((t + (cek/2) - 1e-12)/cek)
      return (eff[idx+1])
    }
}

cf <- function(t) {

  if (t<0)
    {
      return(NA)
    }
  else
    {
      idx <- floor((t+(k/2)-1e-12)/k)
      return(cat[idx+1])
    }
}

x <- matrix(0,nrow=I+1,ncol=J+1)
n <- matrix(0,nrow=I+1,ncol=J+1)
xh <- matrix(0,nrow=I+1,ncol=J+2)
nh <- matrix(0,nrow=I+1,ncol=J+2)
#spb <- matrix(0,nrow=I+1,ncol=J+2)
#SpB <- array(0,dim=I+1)    

for (j in 1:(J+1))
    x[1,j] <- (j-1)*omega/J
x[1,J+1] <- x[1,J+1] - 1e-9

a <- alpha
bb <- beta
gg <- gamma
kk <- kappa
ww <- omega

zeta <- sqrt( 81*kk*kk*ww*ww*(a*A1+2*a*A2*ww)^2 - 12*kk*(a*A1*ww+kk)^3 )
eta <- 9*a*A1*kk*kk*ww + 18*a*A2*kk*kk*ww*ww + kk*zeta
Z <- eta^(1/3) / (3*(2/3)^(1/3)) + (2/3)^(1/3)*kk*(a*A1*ww+kk) / eta^(1/3)

ubar <- (Z-beta-kappa)/gamma
vbar <- (kappa*omega*ubar) / (beta+gamma*ubar+kappa)
wbar <- (2*kappa*omega*vbar) / (beta+gamma*ubar+2*kappa)

for (j in 1:(J+1))
    n[1,j] <- (a*A1*vbar+a*A2*wbar)*(omega-x[1,j])^((beta+gamma*ubar)/kappa - 1) / (kappa*omega^((beta+gamma*ubar)/kappa))

#for (j in 1:(J+1))
#    spb[1,j] <- b(x[1,j])*n[1,j]
#SpB[1] <- Q(x[1,],spb[1,],J+1)
    
Qi <- array(0,dim=I+1)
HF <- array(0,dim=I+1)

Qi[1] <- Q(x[1,],n[1,],J+1)

xn <- array(0,dim=J+2)
nn <- array(0,dim=J+2)

for (i in 2:(I+1)) {

    t <- k*(i-N-2)
    th <- k*(i-N-1.5)

    xh[i,1] <- 1e-9
    for (j in 2:(J+1)) 
      xh[i,j] <- x[i-1,j-1]+(k/2)*g(x[i-1,j-1])
    xh[i,J+2] <- omega

    for (j in 2:(J+2)) 
      nh[i,j] <- n[i-1,j-1]*exp(-(k/2)*zstar(x[i-1,j-1],Qi[i-1],t))
    nh[i,1] <- Q2(xh[i,],nh[i,],g(0),J+2)

    Qhalf <- Q(xh[i,],nh[i,],J+2)
    
    xn[1] <- 1e-9
    for (j in 2:(J+1))
      xn[j] <- x[i-1,j-1] + k*g(xh[i,j])
    xn[J+2] <- omega
 
    for (j in 2:(J+2))
      nn[j] <- n[i-1,j-1]*exp(-k*zstar(xh[i,j],Qhalf,th))
    nn[1] <- Q2(xn,nn,g(0),J+2)

    Qi[i] <- Q(xn,nn,J+2)

    md <- omega
    omit <- -1
    for (j in 2:(J+1)) {
        v <- abs(xn[j-1]-xn[j+1])
        if (v<md) {
            md <- v
            omit <- j
        }
    }

    x[i,] <- xn[-omit]
    n[i,] <- nn[-omit]    
    
    #for (j in 1:(J+2))
    #    spb[i,j] <- b(x[i,j])*n[i,j]
    #SpB[i] <- Q(x[i,],spb[i,],J+i+1)

}

#l <- matrix(0,nrow=Nl,ncol=J+1)
#for (lid in 1:Nl)
#    for (j in 1:(J+2))
#        for (jj in 1:t_s)
#            l[lid,j+1] <- l[lid,j+1] + exp(-((x[t_id[lid],j+1] - lf[lid,jj])/2)^2 ) + 1e-190
#lw <- matrix(0,nrow=Nl,ncol=J+t_id[Nl]+1)

h <- array(0,dim=(I+1))
tt <- array(0,dim=(I+1))

lfi <- 1
for (i in (N+1):(I+1)) {
    
    v <- array(0,J+1)
    
    for (j in 1:(J+1))
        v[j] <- s(x[i,j])*n[i,j]*iota*e(k*(i-N-1))*w(x[i,j])

    if (lfi <= Nl & t_id[lfi]==i) {
        
        l <- array(0,dim=(J+1))
        
        for (j in 1:(J+1))
            for (jj in 1:t_sz[lfi])
                l[j] <- l[j] + exp(-((x[i,j] - lf[lfi,jj])/2)^2 ) + 1e-190

        #lw <- array(0,dim=(J+1))
        
        #for (j in 1:(J+1))
        #    lw[j] <- l[j]*w(x[i,j])

        al <- cf(k*(i-N-1)) / Q(x[i,],l,J+1)
        
        ld <- array(0,dim=(J+1))
        for (j in 1:(J+1))
            ld[j] <- (v[j]-al*l[j])^2
        
        h[i] <- Q(x[i,],ld,J+1)
        
        
        lfi <- lfi + 1
        
    } else {
        
        h[i] <- (Q(x,v,J+1)-cf(k*(i-N-1)))^2

    }
        
    tt[i] <- k*(i-N-1)
}

Q(tt,h,I+1)

#for (lid in 1:Nl) {
#for (j in 0:(J+t_id[lid]))
#lw[lid,j+1] <- l[lid,j+1]*w(x[t_id[lid],j+1])
#al <- cf(k*(t_id[lid]-N)) / Q(x[t_id[lid],1:(J+t_id[lid]+1)],lw[lid,1:(J+t_id[lid]+1)],J+t_id[lid]-1)
#xx <- array(0,dim=J+t_id[lid]+1)
#yy <- array(0,dim=J+t_id[lid]+1)
#zz <- array(0,dim=J+t_id[lid]+1)
#for (j in 1:(J+t_id[lid]+1)) {
#    xx[j] <- x[t_id[lid],j]
#    yy[j] <- al*l[lid,j]
#    zz[j] <- s(x[t_id[lid],j])*n[t_id[lid],j]*iota*e(k*(t_id[lid]-N-1))
#}


@ 

<<plotlf1,echo=FALSE,fig=TRUE,include=FALSE>>=

lfi <- 1

l <- array(0,dim=(J+1))

for (j in 1:(J+1))
    for (jj in 1:t_sz[lfi])
        l[j] <- l[j] + exp(-((x[t_id[lfi],j] - lf[lfi,jj])/2)^2 ) + 1e-190
        
al <- cf(k*(t_id[lfi]-N-1)) / Q(x[t_id[lfi],],l,J+1)

xx <- array(0,dim=J+1)
yy <- array(0,dim=J+1)
zz <- array(0,dim=J+1)

for (j in 1:(J+1)) {
    xx[j] <- x[t_id[lfi],j]
    yy[j] <- al*l[j]
    zz[j] <- s(x[t_id[lfi],j])*n[t_id[lfi],j]*iota*e(k*(t_id[lfi]-N-1))*w(x[t_id[lfi],j])
}
        
plot(xx,yy,ylim=range(c(yy,zz)),xlab="Length (cm)",ylab="Instantaneous catch rate (fish per cm per year)",main=paste(paste("Year:",1990+floor(k*(t_id[lfi]-N-1))),", Model-fortnight: ",floor(20*(k*(t_id[lfi]-N-1)-floor(k*(t_id[lfi]-N-1)))),sep=''))
lines(xx,zz)
legend(x=20,y=.9*Memax(range(c(yy,zz))),c("Predicted","Observed"),lty=c("solid",NA),pch=c(NA,1))

@ 

\begin{figure}
  \includegraphics[width=\textwidth]{spadernw-plotlf1.pdf}
  \caption{Length frequency gof}
  \label{fig:plotlfgof}
\end{figure}


<<plotlf2,echo=FALSE,fig=TRUE,include=FALSE>>=

lfi <- 2

l <- array(0,dim=(J+1))

for (j in 1:(J+1))
    for (jj in 1:t_sz[lfi])
        l[j] <- l[j] + exp(-((x[t_id[lfi],j] - lf[lfi,jj])/2)^2 ) + 1e-190
        
al <- cf(k*(t_id[lfi]-N-1)) / Q(x[t_id[lfi],],l,J+1)

xx <- array(0,dim=J+1)
yy <- array(0,dim=J+1)
zz <- array(0,dim=J+1)

for (j in 1:(J+1)) {
    xx[j] <- x[t_id[lfi],j]
    yy[j] <- al*l[j]
    zz[j] <- s(x[t_id[lfi],j])*n[t_id[lfi],j]*iota*e(k*(t_id[lfi]-N-1))*w(x[t_id[lfi],j])
}
        
plot(xx,yy,ylim=range(c(yy,zz)),xlab="Length (cm)",ylab="Instantaneous catch rate (fish per cm per year)",main=paste(paste("Year:",1990+floor(k*(t_id[lfi]-N-1))),", Model-fortnight: ",floor(20*(k*(t_id[lfi]-N-1)-floor(k*(t_id[lfi]-N-1)))),sep=''))
lines(xx,zz)
legend(x=20,y=.9*Memax(range(c(yy,zz))),c("Predicted","Observed"),lty=c("solid",NA),pch=c(NA,1))

@ 

\begin{figure}
  \includegraphics[width=\textwidth]{spadernw-plotlf2.pdf}
  \caption{Length frequency gof}
  \label{fig:plotlfgof}
\end{figure}


<<plotlf3,echo=FALSE,fig=TRUE,include=FALSE>>=

lfi <- 3

l <- array(0,dim=(J+1))

for (j in 1:(J+1))
    for (jj in 1:t_sz[lfi])
        l[j] <- l[j] + exp(-((x[t_id[lfi],j] - lf[lfi,jj])/2)^2 ) + 1e-190

        
al <- cf(k*(t_id[lfi]-N-1)) / Q(x[t_id[lfi],],l,J+1)

xx <- array(0,dim=J+1)
yy <- array(0,dim=J+1)
zz <- array(0,dim=J+1)

for (j in 1:(J+1)) {
    xx[j] <- x[t_id[lfi],j]
    yy[j] <- al*l[j]
    zz[j] <- s(x[t_id[lfi],j])*n[t_id[lfi],j]*iota*e(k*(t_id[lfi]-N-1))*w(x[t_id[lfi],j])
}
        
plot(xx,yy,ylim=range(c(yy,zz)),xlab="Length (cm)",ylab="Instantaneous catch rate (fish per cm per year)",main=paste(paste("Year:",1990+floor(k*(t_id[lfi]-N-1))),", Model-fortnight: ",floor(20*(k*(t_id[lfi]-N-1)-floor(k*(t_id[lfi]-N-1)))),sep=''))
lines(xx,zz)
legend(x=20,y=.9*Memax(range(c(yy,zz))),c("Predicted","Observed"),lty=c("solid",NA),pch=c(NA,1))

@ 

\begin{figure}
  \includegraphics[width=\textwidth]{spadernw-plotlf3.pdf}
  \caption{Length frequency gof}
  \label{fig:plotlfgof}
\end{figure}


<<plotlf4,echo=FALSE,fig=TRUE,include=FALSE>>=

lfi <- 4

l <- array(0,dim=(J+1))

for (j in 1:(J+1))
    for (jj in 1:t_sz[lfi])
        l[j] <- l[j] + exp(-((x[t_id[lfi],j] - lf[lfi,jj])/2)^2 ) + 1e-190
       
al <- cf(k*(t_id[lfi]-N-1)) / Q(x[t_id[lfi],],l,J+1)

xx <- array(0,dim=J+1)
yy <- array(0,dim=J+1)
zz <- array(0,dim=J+1)

for (j in 1:(J+1)) {
    xx[j] <- x[t_id[lfi],j]
    yy[j] <- al*l[j]
    zz[j] <- s(x[t_id[lfi],j])*n[t_id[lfi],j]*iota*e(k*(t_id[lfi]-N-1))*w(x[t_id[lfi],j])
}
        
plot(xx,yy,ylim=range(c(yy,zz)),xlab="Length (cm)",ylab="Instantaneous catch rate (fish per cm per year)",main=paste(paste("Year:",1990+floor(k*(t_id[lfi]-N-1))),", Model-fortnight: ",floor(20*(k*(t_id[lfi]-N-1)-floor(k*(t_id[lfi]-N-1)))),sep=''))
lines(xx,zz)
legend(x=20,y=.9*Memax(range(c(yy,zz))),c("Predicted","Observed"),lty=c("solid",NA),pch=c(NA,1))

@ 

\begin{figure}
  \includegraphics[width=\textwidth]{spadernw-plotlf4.pdf}
  \caption{Length frequency gof}
  \label{fig:plotlfgof}
\end{figure}

<<eq,echo=FALSE>>=
eq <- function(x) { (a*A1*vbar+a*A2*wbar)*(omega-x)^((beta+gamma*ubar)/kappa - 1) / (kappa*omega^((beta+gamma*ubar)/kappa)) }
@ 

<<ploteq,echo=FALSE,fig=TRUE,include=FALSE>>=
xs <- seq(0,omega,length.out=300)
plot(xs,eq(xs),type='l',xlab='Size (cm)',ylab='Population (number density)')
#points(X[1000,],U[1000,],col='red')
@ 

<<plotti,echo=FALSE,fig=TRUE,include=FALSE>>=
plot(Qi,type='l')
@ 

\begin{figure}
  \includegraphics[width=\textwidth]{spadernw-ploteq.pdf}
  \caption{Size distribution at equilibrium.}
  \label{fig:ploteq}
\end{figure}

\begin{table}
  \centering
\begin{tabular}{|c|c|c|c|}
\hline
Process & Symbol & Units & Value\\
\hline
\multirow{2}{*}{Birth}
 & $\alpha$  & $\text{cm}^{-1}\text{yr}^{-1}$  & \\
% & $\alpha_2$  & $\text{cm}^{-1}\text{yr}^{-1}$  & \\
\hline
\multirow{2}{*}{Growth}
 & $\kappa$   & $\text{yr}^{-1}$  & \\
 & $\omega$ & $\text{cm}$ & \\
\hline
\multirow{2}{*}{Natural Death}
 & $\beta$  & $\text{yr}^{-1}$ & \\
 & $\gamma$  & $\text{fish}^{-1}\text{yr}^{-1}$  & \\
\hline 
\multirow{1}{*}{Fishing Death}
 & $\iota$  & $\text{yr}^{-1}$ & \\
\hline
\end{tabular}
\caption{Active parameters}
\label{tbl:active}
\end{table}

\section{Discussion}\label{sec:disc}
Very sensible to have an age dependent death rate. Plasticity. Incoherence of standard probabilistic growth models. Identifiability. Granularity and scale.

Call for greater interaction between fishery modellers, numerical analysts, and mathematicians that specialise in reducing PDEs to ODEs, and manipulating PDEs. 

There is insight.


We end with a stronger, more controversial statement: if you can't get analytic gradients, perhaps you don't know what you're doing. (because you don't have a deep understanding of the uncertainty)

As noted by \citet{Lorenzen2008}, the traditional `stock and recruitment' configuration misses the fact that significant density dependent effects occur after recruitment. 

Mention the debate over mortality and whether or not it should be estimated within a stock assessment model.

\citet{Schnute1991}

\clearpage
\begin{appendices}  
\section{Sensitivity PDEs}\label{app:pde}
\begin{subequations}
  \begin{align}
  \frac{d F}{d \alpha} &= p_t + \kappa(\omega-x)p_x - \kappa p + \left(\beta+\gamma U+s(x)\iota e(t)\right)p + \gamma P u = 0\\
  \frac{d F}{d \beta} &= p_t + \kappa(\omega-x)p_x - \kappa p + \left(\beta+\gamma U+s(x)\iota e(t)\right)p + \left(1+ \gamma P\right)u = 0 \\
  \frac{d F}{d \gamma} &= p_t + \kappa(\omega-x)p_x - \kappa p + \left(\beta+\gamma U+s(x)\iota e(t)\right)p + \left(U+ \gamma P\right)u = 0 \\
  \frac{d F}{d \kappa} &= p_t + (\omega-x)u_x + \kappa(\omega-x)p_x - \kappa p - u + \left(\beta+\gamma U+s(x)\iota e(t)\right)p + \gamma P u = 0 \\
  \frac{d F}{d \omega} &= p_t + \kappa u_x + \kappa(\omega-x)p_x - \kappa p + \left(\beta+\gamma U+s(x)\iota e(t)\right)p + \gamma P u = 0 \\  
  \frac{d F}{d \iota} &= p_t + \kappa(\omega-x)p_x - \kappa p + \left(\beta+\gamma U+s(x)\iota e(t)\right)p + \left(s(x)e(t)+\gamma P\right) u = 0 
  \end{align}
\end{subequations}
The boundary conditions for each case are given by
\begin{subequations}
  \begin{align}
    \kappa\omega p(0,t) &= \int_0^\omega \left(a_1 x + a_2 x^2\right) \left(\alpha p(x,t) + u(x,t)\right)\,dx \\
    \kappa\omega p(0,t) &= \int_0^\omega \alpha \left(a_1 x + a_2 x^2\right) p(x,t) \,dx \\
    \kappa\omega p(0,t) &= \int_0^\omega \alpha \left(a_1 x + a_2 x^2\right) p(x,t) \,dx \\
    \omega u(0,t) + \kappa\omega p(0,t) &= \int_0^\omega \alpha \left(a_1 x + a_2 x^2\right) p(x,t) \,dx \\
    \kappa u(0,t) + \kappa\omega p(0,t) &= \int_0^\omega \alpha \left(a_1 x + a_2 x^2\right) p(x,t) \,dx \\
    \kappa\omega p(0,t) &= \int_0^\omega \alpha \left(a_1 x + a_2 x^2\right) p(x,t)  \,dx  
  \end{align}
\end{subequations}

\clearpage
\section{PDE characteristic integrals}\label{app:sol}
\begin{equation}
  \begin{split}
    q(t&;t^*,x^*)=p(x^*,t^*)\exp\left(-\int_{t^*}^t z^*(x(\tau;x^*,t^*),U(\tau),\tau)\,d\tau\right) -\\
    & \phantom{(;t^*,x^*)=p(x^*,t^*)}\exp\left(-\int_{t^*}^t z^*(x(\tau;x^*,t^*),U(\tau),\tau)\,d\tau\right)\times\\
    & \int_{t^*}^t m(x(\tau;t^*,x^*),P(\tau),u(x(\tau;t^*,x^*),\tau),\tau) \exp\left(\int_{t^*}^\tau z^*(x(\zeta;x^*,t^*),U(\zeta),\zeta)\,d\zeta\right)\,d\tau
  \end{split}
\end{equation}
where
\begin{equation}
  q(t;t^*,x^*)=p(x(t;t^*,x^*),t)
\end{equation}
and
\begin{equation}
  m(x,P(t),u(x,t),t)= 
  \begin{cases}
    \gamma P(t) u(x,t) & \text{if } \alpha \\
    \left(1 + \gamma P(t)\right) u(x,t) & \text{if } \beta \\
    \left(U(t) + \gamma P(t)\right) u(x,t) & \text{if } \gamma \\
    \left(\gamma P(t) - 1\right)u(x,t) + (\omega-x) u_x(x,t) & \text{if } \kappa\\
    \gamma P(t) u(x,t) + \kappa u_x(x,t) & \text{if } \omega \\
    \left(s(x)e(t)+\gamma P(t)\right) u(x,t) & \text{if } \iota
  \end{cases}
\end{equation}

\clearpage
\section{Numerics}\label{app:num}
\begin{algorithm}
  \caption{Model PDE numerical solution}\label{alg:base}
  \begin{algorithmic}
    \State $X_0^{n+1} \gets 0$
    \State $X_{j+1}^{n+1} \gets X_j^n + k g(X_{j+1}^{n+1/2}), 0 \leq j \leq J$
    \State $U_{j+1}^{n+1} \gets U_j^n \exp\left(-k z^*(X_{j+1}^{n+1/2},\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}),t^{n+1/2})\right), 0 \leq j \leq J$
    \State $U_0^{n+1} \gets \mathcal{Q}(\mathbf{X}^{n+1},b(\mathbf{U}^{n+1})) / g(X_{0}^{n+1})$
    \State $X_0^{n+1/2} \gets 0$
    \State $X_{j+1}^{n+1/2} \gets X_j^n + (k/2) g(X_{j+1}^{n+1/4}), 0 \leq j \leq J$
    \State $U_{j+1}^{n+1/2} \gets U_j^n \exp\left(-(k/2) z^*(X_{j+1}^{n+1/4},\mathcal{Q}(\mathbf{X}^{n+1/4},\mathbf{U}^{n+1/4}),t^{n+1/4})\right), 0 \leq j \leq J$
    \State $U_0^{n+1/2} \gets \mathcal{Q}(\mathbf{X}^{n+1/2},b(\mathbf{U}^{n+1/2})) / g(X_{0}^{n+1/2})$
    \State $X_{j+1}^{n+1/4} \gets X_j^n + (k/4) g(X_{j}^{n}), 0 \leq j \leq J$
    \State $U_{j+1}^{n+1/4} \gets U_j^n \exp\left(-(k/4) z^*(X_{j}^{n},\mathcal{Q}(\mathbf{X}^{n},\mathbf{U}^{n}),t^{n})\right), 0 \leq j \leq J$
    \State $U_0^{n+1/4} \gets \mathcal{Q}(\mathbf{X}^{n+1/4},b(\mathbf{U}^{n+1/4})) / g(X_{0}^{n+1/4})$
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Sensitivity PDE numerical solution for $\alpha$, $\beta$, $\gamma$ and $\iota$}\label{alg:sens1}
  \begin{algorithmic}
    \State $P_{j+1}^{n+1/2} \gets P_j^n \exp\left(-(k/2)z^*(X_{j}^{n},\mathcal{Q}(\mathbf{X}^{n},\mathbf{U}^{n}),t^{n})\right)-\exp\left(-(k/2)z^*(X_{j}^{n},\mathcal{Q}(\mathbf{X}^{n},\mathbf{U}^{n}),t^{n})\right)\times$\\ \hspace{1cm} 
    $\begin{cases} (k/2)\gamma\mathcal{Q}(\mathbf{X}^n,\mathbf{P}^n)U_j^n & \text{if }\alpha \\ (k/2)\left(1+\gamma\mathcal{Q}(\mathbf{X}^n,\mathbf{P}^n)\right)U_j^n & \text{if }\beta \\ (k/2)\left(\mathcal{Q}(\mathbf{X}^n,\mathbf{U}^n)+\gamma\mathcal{Q}(\mathbf{X}^n,\mathbf{P}^n)\right)U_j^n & \text{if }\gamma \\ (k/2)\left(s(X_j^n)e(t^n)+\gamma\mathcal{Q}(\mathbf{X}^n,\mathbf{P}^n)\right)U_j^n & \text{if }\iota\end{cases}$
    \State $P_0^{n+1/2} \gets \mathcal{Q}(\mathbf{X}^{n+1/2},b(\mathbf{P}^{n+1/2})) / g(X_0^{n+1/2})$
    \State $P_{j+1}^{n+1} \gets P_j^n \exp\left(-k z^*(X_{j+1}^{n+1/2},\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}),t^{n+1/2})\right)-$\\ \hspace{1cm} $\exp\left(-k z^*(X_{j+1}^{n+1/2},\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}),t^{n+1/2})\right)\times$\\ \hspace{1cm} $\begin{cases}k\gamma\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{P}^{n+1/2})U_j^{n+1/2} & \text{if } \alpha \\ k\left(1+\gamma\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{P}^{n+1/2})\right)U_j^{n+1/2} & \text{if } \beta \\ k\left(\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}) + \gamma\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{P}^{n+1/2})\right)U_j^{n+1/2} & \text{if } \gamma \\ k\left(s(X_{j+1}^{n+1/2})e(t^{n+1/2})+\gamma\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{P}^{n+1/2})\right)U_{j+1}^{n+1/2} & \text{if } \iota \end{cases}$\hspace{1cm}$\times$\\ \hspace{1cm} $ \exp\left((k/2)z^*(X_{j+1}^{n+1/4},\mathcal{Q}(\mathbf{X}^{n+1/4},\mathbf{U}^{n+1/4}),t^{n+1/4})\right)$
    \State $P_0^{n+1} \gets \mathcal{Q}(\mathbf{X}^{n+1},b(\mathbf{P}^{n+1})) / g(X_0^{n+1})$
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Sensitivity PDE numerical solution for $\kappa$ and $\omega$}\label{alg:sens2}
  \begin{algorithmic}
    \State $P_{1}^{n+1/2} \gets P_0^n \exp\left(-(k/2)z^*(X_{0}^{n},\mathcal{Q}(\mathbf{X}^{n},\mathbf{U}^{n}),t^{n})\right)-\exp\left(-(k/2)z^*(X_{0}^{n},\mathcal{Q}(\mathbf{X}^{n},\mathbf{U}^{n}),t^{n})\right)\times$\\ \hspace{1cm} $(k/2)\begin{cases}\left(\left(\gamma\mathcal{Q}(\mathbf{X}^n,\mathbf{P}^n)-1\right)U_0^n + \left(\omega-X_0^n\right)\left(U_1^n - U_0^n\right) / (X_1^n - X_0^n)\right) & \text{if } \kappa \\ \gamma\mathcal{Q}(\mathbf{X}^n,\mathbf{P}^n)U_0^n + \kappa(U_1^n - U_0^n) / (X_1^n - X_0^n) & \text{if } \omega \end{cases}$ 
    \State $P_{j+1}^{n+1/2} \gets P_j^n \exp\left(-(k/2)z^*(X_{j}^{n},\mathcal{Q}(\mathbf{X}^{n},\mathbf{U}^{n}),t^{n})\right)-\exp\left(-(k/2)z^*(X_{j}^{n},\mathcal{Q}(\mathbf{X}^{n},\mathbf{U}^{n}),t^{n})\right)\times$\\ \hspace{.2cm} $(k/2)\begin{cases} \bigg(\left(\gamma\mathcal{Q}(\mathbf{X}^n,\mathbf{P}^n)-1\right)U_j^n + \\ \left(\omega-X_j^n\right).5\left( (U_{j+1}^n - U_{j}^n) / (X_{j+1}^n - X_{j}^n) + (U_{j}^n - U_{j-1}^n) / (X_{j}^n - X_{j-1}^n)\right) \bigg) & \text{if } \kappa \\ \gamma\mathcal{Q}(\mathbf{X}^n,\mathbf{P}^n)U_j^n + \kappa .5\left( (U_{j+1}^n - U_{j}^n) / (X_{j+1}^n - X_{j}^n) + (U_{j}^n - U_{j-1}^n) / (X_{j}^n - X_{j-1}^n)\right) & \text{if } \omega \end{cases}$\\ \hspace{.5cm},$1 \leq j \leq J$
    \State $P_0^{n+1/2} \gets \begin{cases} \left(\mathcal{Q}(\mathbf{X}^{n+1/2},b(\mathbf{P}^{n+1/2})) - \omega U_0^{n+1/2} \right) / g(X_0^{n+1/2}) & \text{if } \kappa \\ \left(\mathcal{Q}(\mathbf{X}^{n+1/2},b(\mathbf{P}^{n+1/2})) - \kappa U_0^{n+1/2} \right) / g(X_0^{n+1/2}) & \text{if } \omega \end{cases}$  
    \State $P_{j+1}^{n+1} \gets P_j^n \exp\left(-k z^*(X_{j+1}^{n+1/2},\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}),t^{n+1/2})\right)-$\\ \hspace{1cm} $\exp\left(-k z^*(X_{j+1}^{n+1/2},\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}),t^{n+1/2})\right)\times$\\ \hspace{.5cm} $k\begin{cases}\bigg(\left(\gamma\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{P}^{n+1/2})-1\right)U_{j+1}^{n+1/2} + \\ \left(\omega-X_j^n\right).5\left( (U_{j+1}^{n+1/2} - U_{j}^{n+1/2}) / (X_{j+1}^{n+1/2} - X_{j}^{n+1/2}) + (U_{j}^{n+1/2} - U_{j-1}^{n+1/2}) / (X_{j}^{n+1/2} - X_{j-1}^{n+1/2})\right) \bigg) & \text{if } \kappa \\  \bigg(\gamma\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{P}^{n+1/2})U_{j+1}^{n+1/2} + \\ \kappa .5\left( (U_{j+1}^{n+1/2} - U_{j}^{n+1/2}) / (X_{j+1}^{n+1/2} - X_{j}^{n+1/2}) + (U_{j}^{n+1/2} - U_{j-1}^{n+1/2}) / (X_{j}^{n+1/2} - X_{j-1}^{n+1/2})\right) \bigg) & \text{if } \omega \end{cases}   \times$\\ \hspace{1cm} $ \exp\left((k/2)z^*(X_{j+1}^{n+1/4},\mathcal{Q}(\mathbf{X}^{n+1/4},\mathbf{U}^{n+1/4}),t^{n+1/4})\right)$\hspace{.5cm},$1 \leq j \leq J-1$
    \State $P_{J+1}^{n+1} \gets P_J^n \exp\left(-k z^*(X_{J+1}^{n+1/2},\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}),t^{n+1/2})\right)-$\\ \hspace{1cm} $\exp\left(-k z^*(X_{J+1}^{n+1/2},\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{U}^{n+1/2}),t^{n+1/2})\right)\times$\\ \hspace{1cm} $k\begin{cases}\left(\gamma\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{P}^{n+1/2})-1\right)U_{J+1}^{n+1/2} & \text{if } \kappa \\ \gamma\mathcal{Q}(\mathbf{X}^{n+1/2},\mathbf{P}^{n+1/2})U_{J+1}^{n+1/2} & \text{if } \omega \end{cases}$\hspace{.2cm} $\times$\\ \hspace{1cm} $ \exp\left((k/2)z^*(X_{J+1}^{n+1/4},\mathcal{Q}(\mathbf{X}^{n+1/4},\mathbf{U}^{n+1/4}),t^{n+1/4})\right)$
    \State $P_0^{n+1} \gets \begin{cases} \left(\mathcal{Q}(\mathbf{X}^{n+1},b(\mathbf{P}^{n+1})) - \omega U_0^{n+1} \right) / g(X_0^{n+1}) & \text{if } \kappa \\ \left(\mathcal{Q}(\mathbf{X}^{n+1},b(\mathbf{P}^{n+1})) - \kappa U_0^{n+1} \right) / g(X_0^{n+1}) & \text{if } \omega \end{cases}$
  \end{algorithmic}
\end{algorithm}

\clearpage
\section{Analytical Equilibrium Derivations}\label{app:eq}
\emph{Part one - Sub \ref{eq:growth} and \ref{eq:birth} into \ref{eq:1.1} and integrate over $x$ from 0 to $\omega$.}

\begin{subequations}
  \begin{align}
    \int_0^{\omega} u_t(x,t)\,dx + \int_0^{\omega} [\kappa(\omega-x)u(x,t)]_x \, dx &= \int_0^{\omega} -(\beta+\gamma U(t)) u(x,t)\, dx\\
%    \Rightarrow \dot{U}(t) + \int_0^{\omega} \kappa(\omega-x)u_x(x,t)\,dx - \int_0^{\omega} \kappa u(x,t)\,dx&= -(\beta+\gamma U(t)) U(t)\\
    \Rightarrow \dot{U}(t) + \int_0^{\omega} \kappa(\omega-x)u_x(x,t)\,dx - \kappa  U(t) &= -(\beta+\gamma U(t)) U(t)\label{eq:1pt3}
  \end{align}
\end{subequations}

Integrating the second term in \ref{eq:1pt3} by parts:
%\begin{equation*}
%  \upsilon=\kappa(\omega - x),~~~d\nu=u_x(x,t)\,dx,~~~d\upsilon=-\kappa\,dx,~~~\nu=u(x,t)
%\end{equation*}

\begin{subequations}
  \begin{align*}
    &\kappa(\omega-x) u(x,t)]_0^{\omega} - \int_0^{\omega} u(x,t) (-\kappa)\,dx\\
    %&\Rightarrow \kappa(\omega - \omega)u(\omega,t) - \kappa(\omega-0)u(0,t) + \kappa U(t)\\
      &\Rightarrow \kappa U(t) - \kappa(\omega-0)u(0,t)
  \end{align*}
\end{subequations}
subbing back:
\begin{subequations}
  \begin{align}
    &\dot{U}(t) + \kappa U(t) - \kappa(\omega-0)u(0,t) - \kappa  U(t) = -(\beta+\gamma U(t)) U(t)\\
    %&\Rightarrow \dot{U}(t) = -(\beta+\gamma U(t)) U(t) + \kappa(\omega-0)u(0,t)\\
    %&\Rightarrow \dot{U}(t) = -(\beta+\gamma U(t)) U(t) + \int_0^\omega b(x) u(x,t)\, dx\\
    %&\Rightarrow \dot{U}(t) = -(\beta+\gamma U(t)) U(t) + \int_0^\omega \left( \alpha_1 x u(x,t) + \alpha_2 x^2 u(x,t) \right) \, dx\\
    %&\Rightarrow \dot{U}(t) = -(\beta+\gamma U(t)) U(t) + \int_0^\omega \alpha_1 x u(x,t)\, dx + \int_0^\omega \alpha_2 x^2 u(x,t) \, dx\\
    &\Rightarrow \dot{U}(t) = -(\beta+\gamma U(t)) U(t) + \alpha_1 V(t) + \alpha_2 W(t)
  \end{align}
\end{subequations}

\noindent\emph{Part two - sub \ref{eq:growth} and \ref{eq:birth} into \ref{eq:1.1}, multiply by $x$ and integrate over $x$ from 0 to $\omega$.}

\begin{subequations}
  \begin{align}
    \int_0^{\omega} u_t(x,t)x\,dx + \int_0^{\omega} [\kappa(\omega-x)u(x,t)]_x x \, dx &= \int_0^{\omega} -(\beta+\gamma U(t)) u(x,t)x\, dx\\
    %\Rightarrow \dot{V}(t) + \int_0^{\omega} x\kappa(\omega-x)u_x(x,t)\,dx - \int_0^{\omega} x\kappa u(x,t)\,dx &= -(\beta+\gamma U(t)) V(t)\\
    \Rightarrow \dot{V}(t) + \int_0^{\omega} x\kappa(\omega-x)u_x(x,t)\,dx - \kappa V(t) &= -(\beta+\gamma U(t)) V(t)\label{eq:2pt3}
  \end{align}
\end{subequations}
Integrating the second term in \ref{eq:2pt3} by parts:
%\begin{equation*}
%  \upsilon=x\kappa(\omega - x),~~~d\nu=u_x(x,t)\,dx,~~~d\upsilon=\kappa \omega - 2\kappa x \,dx,~~~\nu=u(x,t)
%\end{equation*}

\begin{subequations}
  \begin{align*}
    &\left. x\kappa(\omega - x) u(x,t) \right]_0^{\omega} - \int_0^{\omega} u(x,t) \left[ \kappa \omega - 2 \kappa x \right] \,dx\\
    %&\Rightarrow \left. x\kappa(\omega -x) u(x,t) \right]_0^{\omega} - \int_0^{\omega} \kappa \omega u(x,t)\,dx + \int_0^{\omega} 2\kappa x u(x,t)\,dx\\
    &\Rightarrow 2\kappa V(t) - \kappa \omega U(t) 
  \end{align*}
\end{subequations}

subbing back into \ref{eq:2pt3}
\begin{subequations}
  \begin{align*}
    &\dot{V}(t) + 2\kappa V(t) - \kappa \omega U(t) - \kappa V(t) = -(\beta+\gamma U(t)) V(t)\\
    %&\Rightarrow \dot{V}(t) + \kappa V(t) - \kappa \omega U(t) = -(\beta+\gamma U(t)) V(t)\\
    &\Rightarrow \dot{V}(t) = -(\beta+\gamma U(t)) V(t) + \kappa \omega U(t) - \kappa V(t)
  \end{align*}
\end{subequations}

%\clearpage
\noindent\emph{Part three - sub \ref{eq:growth} and \ref{eq:birth} into \ref{eq:1.1}, multiply by $x^2$ and integrate over $x$ from 0 to $\omega$.}

\begin{subequations}
  \begin{align}
    \int_0^{\omega} u_t(x,t)x^2\,dx + \int_0^{\omega} [\kappa(\omega-x)u(x,t)]_x x^2 \, dx &= \int_0^{\omega} -(\beta+\gamma U(t)) u(x,t)x^2\, dx\\
    %\Rightarrow \dot{W}(t) + \int_0^{\omega} x^2\kappa(\omega-x)u_x(x,t)\,dx - \int_0^{\omega} x^2\kappa u(x,t)\,dx &= -(\beta+\gamma U(t)) W(t)\\
    \Rightarrow \dot{W}(t) + \int_0^{\omega} x^2\kappa(\omega-x)u_x(x,t)\,dx - \kappa W(t) &= -(\beta+\gamma U(t)) W(t)\label{eq:2pt3}
  \end{align}
\end{subequations}
Integrating the second term in \ref{eq:2pt3} by parts:
%\begin{equation*}
%  \upsilon=x^2\kappa(\omega - x),~~~d\nu=u_x(x,t)\,dx,~~~d\upsilon=2\kappa \omega x - 3\kappa x^2 \,dx,~~~\nu=u(x,t)
%\end{equation*}

\begin{subequations}
  \begin{align*}
    &\left. x^2 \kappa(\omega - x) u(x,t) \right]_0^{\omega} - \int_0^{\omega} u(x,t) \left[ 2\kappa \omega x - 3 \kappa x^2 \right] \,dx\\
    %&\Rightarrow \left. x\kappa(\omega -x) u(x,t) \right]_0^{\omega} - \int_0^{\omega} 2\kappa \omega x u(x,t)\,dx + \int_0^{\omega} 3\kappa x^2 u(x,t)\,dx\\
    &\Rightarrow 3\kappa W(t) - 2 \kappa \omega V(t) 
  \end{align*}
\end{subequations}

subbing back into \ref{eq:2pt3}
\begin{subequations}
  \begin{align*}
    &\dot{W}(t) + 3\kappa W(t) - 2\kappa \omega V(t) - \kappa W(t) = -(\beta+\gamma U(t)) W(t)\\
    %&\Rightarrow \dot{W}(t) + 2\kappa W(t) - 2\kappa \omega V(t) = -(\beta+\gamma U(t)) W(t)\\
    &\Rightarrow \dot{W}(t) = -(\beta+\gamma U(t)) W(t) + 2\kappa \omega V(t) - 2\kappa W(t)
  \end{align*}
\end{subequations}

\subsection{Solving for $\bar{U}$, $\bar{V}$ and $\bar{W}$}\label{sec:solv}
We can simplify \ref{seq:eqb} to
\begin{equation}
  \bar{V} = \frac{\kappa \omega \bar{U} }{\beta + \gamma \bar{U} + \kappa}\label{eq:6}
\end{equation}
and \ref{seq:eqc} to 
\begin{equation}
  \bar{W} = \frac{2\kappa\omega\bar{V}}{\beta + \gamma\bar{U} + 2\kappa}\label{eq:7}
\end{equation}

Then let $Z=\beta + \gamma\bar{U}+\kappa$ so that
\begin{equation}\label{eqn:Z}
  \begin{split}
   (Z-\kappa) \frac{Z-\beta-\kappa}{\gamma} &= \frac{\alpha a_1 \kappa\omega (Z-\beta-\kappa)}{\gamma Z} + \frac{\alpha a_2 2 \kappa\omega \frac{\kappa\omega(Z-\beta-\kappa)}{\gamma Z}}{Z+\kappa}\\   
%    \frac{Z-\kappa}{\gamma} &= \frac{\alpha_1 \kappa\omega}{\gamma Z} + \frac{\alpha_2 2 \kappa\omega \frac{\kappa\omega}{\gamma Z}}{Z+\kappa}\\
%    Z^2-\kappa Z - \alpha_1 \kappa\omega &= \frac{\alpha_2 2 \kappa\omega \kappa\omega}{Z+\kappa}\\
%    \left(Z+\kappa\right)\left(Z^2-\kappa Z - \alpha_1 \kappa\omega\right) &= \alpha_2 2 \kappa\omega \kappa\omega\\
%    Z^3 - \kappa Z^2 - \alpha_1\kappa\omega Z + \kappa Z^2 - \kappa^2 Z - \alpha_1 \kappa^2 \omega &= \alpha_2 2 \kappa\omega \kappa\omega\\
%    Z^3 - \alpha_1\kappa\omega Z - \kappa^2 Z - \alpha_1 \kappa^2 \omega &= \alpha_2 2 \kappa\omega \kappa\omega\\
    Z^3 - \kappa(\alpha a_1 \omega+\kappa)Z - \kappa\omega (\alpha a_1 \kappa + 2 \alpha a_2 \kappa\omega) &= 0
  \end{split}
\end{equation}

The real solution of this is
\begin{equation}
  Z = \frac{ \sqrt[3]{9 \alpha a_1 \kappa^2 \omega+18 \alpha a_2 \kappa^2 \omega^2+\kappa\zeta}}{3 \sqrt[3]{\frac23}} +  
  \frac{\sqrt[3]{\frac23}\,\kappa (\alpha a_1  \omega+\kappa)}{\sqrt[3]{9 \alpha a_1 \kappa^2 \omega+18 \alpha a_2 \kappa^2 \omega^2+\kappa\zeta}}
\end{equation}  
where
\begin{equation}
\zeta= \sqrt{ 81 \kappa^2 \omega^2 (\alpha a_1 +2 \alpha a_2 \omega)^2 - 12\kappa( \alpha a_1  \omega+ \kappa)^3}.
\end{equation}  


\clearpage
\section{Initial state for sensitivity PDEs}\label{app:2}

%%%%%%%%%%%%%% a_1

We can simplify function $U(x)$ in a following way
Simplifying $U(x)$
\begin{equation}\label{eq:U2}
 \begin{split}
  U(x) = \frac{Z-\beta-\kappa}{\gamma Z}\left(\alpha a_1 + \frac{2\alpha a_2 \kappa\omega}{Z+k}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}.
  \end{split}
\end{equation}

%\begin{equation}\label{eq:U}
% \begin{split}
%  U(x) &=  \frac{ \left(\alpha_1\bar{V}+\alpha_2\bar{W}\right)(\omega-x)^{(\beta+\gamma\bar{U})/\kappa -1} }{\kappa\omega^{(\beta+\gamma\bar{U})/\kappa}} \\ 
%  &=\frac{\alpha_1\bar{V}+\alpha_2\bar{W}}{\kappa(\omega-x)}\left(1-\frac{x}{\omega}\right)^{(\beta+\gamma\bar{U})/\kappa}\\  
%  &=\frac{\alpha_1 \frac{\kappa\omega (Z-\beta-\kappa)}{\gamma Z} +\alpha_2\frac{2\kappa^2\omega^2(Z-\beta-\kappa)}{\gamma Z (Z+k)}}{\kappa(\omega-x)}\left(1-\frac{x}{\omega}\right)^{(Z-\kappa)/\kappa}\\
%    &=\frac{Z-\beta-\kappa}{\gamma Z}\left(\alpha_1 + \frac{2\alpha_2 \kappa\omega}{Z+k}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}.
%  \end{split}
%\end{equation}

{\bf 1.} Now for the first parameter we have

\begin{equation}\label{eq:da}
\begin{split}
  \frac{d u(x)}{d\alpha} =& \frac{(\beta+\kappa)Z_{\alpha}}{\gamma Z^2}\left(\alpha a_1 + \frac{2\alpha a_2 \kappa\omega}{Z+\kappa}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}+\\
&  \frac{Z-\beta-\kappa}{\gamma Z}\left(a_1+ \frac{2 a_2 \kappa\omega}{Z+\kappa}-\frac{2 \alpha a_2\kappa\omega}{(Z+\kappa)^2}Z_{\alpha}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}+\\ 
& \frac{Z-\beta-\kappa}{\gamma Z}\left(\alpha a_1+ \frac{2\alpha a_2 \kappa\omega}{Z+\kappa}
\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}\log\left(1-\frac{x}{\omega}\right)\frac{Z_{\alpha}}{\kappa}, 
  \end{split}
\end{equation}
which can be written as
\begin{equation}\begin{split}
\left(1-\frac{x}{\omega}\right)^{\frac{Z}{\kappa}-2}&\left[ 
\frac{Z-\beta-\kappa}{\gamma Z}\left(a_1+ \frac{2 a_2 \kappa\omega}{Z+\kappa}-\frac{2 \alpha a_2\kappa\omega}{(Z+\kappa)^2}Z_{\alpha}\right) + \right.\\
&\left.+\frac{Z_{\alpha}}{\gamma Z}\left(\alpha a_1 + \frac{2\alpha a_2 \kappa\omega}{Z+\kappa}\right)
  \left(\frac{\beta+\kappa}{Z}+ \log\left(1-\frac{x}{\omega}\right)\frac{Z-\beta-\kappa}{\kappa}\right) \right], 
\end{split}\end{equation}
where
\begin{equation}\begin{split}
Z_{\alpha}= &\frac{\kappa^2 \omega\,(3 a_1 \zeta+6 a_2  \omega \zeta -6 a_1 (\kappa+\alpha a_1 \omega)^2 + 27\kappa\omega( a_1  + 2 a_2 \omega)(\alpha a_1 + 2 \alpha a_2 \omega))}
{\zeta\, (9 \alpha a_1 \kappa^2 \omega + 18 \alpha a_2 \kappa^2 \omega^2 + \kappa \zeta)^{2/3}}\left(
\frac1{2^{1/3}3^{2/3}}-\right.\\
&\left. \frac{(2/3)^{1/3} \kappa ( \kappa + \alpha a_1\omega)}{(9 \alpha a_1 \kappa^2 \omega + 18 \alpha a_2 \kappa^2 \omega^2 + \kappa \zeta)^{2/3}}\right)+\frac{(2/3)^{1/3}a_1 \kappa\omega}{(9 \alpha a_1 \kappa^2 \omega + 18 \alpha a_2 \kappa^2 \omega^2 + \kappa \zeta)^{1/3}}.
\end{split}\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% k

\bigskip

{\bf 2.} The next one is
\begin{equation}\label{eq:dk}
\begin{split}
  \frac{d u(x)}{d\kappa} =& \frac{(\beta+\kappa)Z_{\kappa}-Z}{\gamma Z^2}\left(\alpha_1 + \frac{2\alpha_2 \kappa\omega}{Z+\kappa}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}+\\
&  \frac{Z-\beta-\kappa}{\gamma Z} \left(\frac{2\alpha_2\omega}{Z+\kappa}-\frac{2\alpha_2\kappa\omega}{(Z+\kappa)^2}(Z_{\kappa}+1)\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}+\\ 
& \frac{Z-\beta-\kappa}{\gamma Z}\left(\alpha_1+ \frac{2\alpha_2 \kappa\omega}{Z+\kappa}
\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}\log\left(1-\frac{x}{\omega}\right)\left(\frac{Z_{\kappa}}{\kappa}-\frac{Z}{\kappa^2}\right), 
  \end{split}
\end{equation}
that is 
\begin{equation}\begin{split}
&\left(1-\frac{x}{\omega}\right)^{\frac{Z}{\kappa}-2} \left[ 
\frac{Z_{\kappa}}{\gamma Z }\left(\left(\alpha_1 + \frac{2\alpha_2 \kappa\omega}{Z+\kappa}\right)
  \left(\frac{\beta+\kappa}{Z}+ \log\left(1-\frac{x}{\omega}\right)\frac{Z-\beta-\kappa}{\kappa}\right)-\frac{2\alpha_2\kappa\omega(Z-\beta-\kappa)}{(Z+\kappa)^2} \right)+ \right.\\
  &\left.  \frac{Z-\beta-\kappa}{\gamma Z (Z+\kappa)}\left(2\alpha_2\omega + \frac{2\alpha_2\kappa\omega}{Z+\kappa}\right) - \left(\alpha_1 + \frac{2\alpha_2 \kappa\omega}{Z+\kappa}\right)\left(\frac1{\gamma Z}+\log\left(1-\frac{x}{\omega}\right)\frac{Z-\beta-\kappa}{\gamma\kappa^2} \right)       \right]
  \end{split}
\end{equation}

where
\begin{equation}\begin{split}
Z_{\kappa}=& \frac{6 \kappa\, (\alpha_1  \omega \zeta + 2 \alpha_2  \omega^2 \zeta - 
      (2 \kappa + \alpha_1 \omega) ( \kappa + \alpha_1  \omega)^2 + 9 \kappa \omega^2 ( \alpha_1 + 2 \alpha_2  \omega)^2)}{\zeta\, (9 \alpha_1 \kappa^2 \omega + 18 \alpha_2 \kappa^2 \omega^2 +\kappa \zeta)^{2/3}}\left( \frac{1}{ 2^{1/3}3^{2/3}} -\right. \\
    &\left.\frac{(2/3)^{1/3} \kappa ( \kappa +  \alpha_1  \omega)}{(9 \alpha_1 \kappa^2 \omega + 18 \alpha_2 \kappa^2 \omega^2 +\kappa \zeta)^{2/3}} \right) + \frac{ (2/3)^{1/3}( 2 \kappa +  \alpha_1 \omega)}{ (9 \alpha_1 \kappa^2 \omega + 18 \alpha_2 \kappa^2 \omega^2 +\kappa \zeta)^{1/3}}.
  \end{split}\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% omega

\bigskip

{\bf 3.} For the parameter $\omega$ we have
\begin{equation}\label{eq:dw}
\begin{split}
  \frac{d u(x)}{d\omega} =& \frac{(\beta+\kappa)Z_{\omega}}{\gamma Z^2}\left(\alpha_1 + \frac{2\alpha_2 \kappa\omega}{Z+\kappa}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}+\\
&  \frac{Z-\beta-\kappa}{\gamma Z} \left(\frac{2\alpha_2\kappa}{Z+\kappa}-\frac{2\alpha_2\kappa\omega}{(Z+\kappa)^2}Z_{\omega}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}+\\ 
& \frac{Z-\beta-\kappa}{\gamma Z}\left(\alpha_1+ \frac{2\alpha_2 \kappa\omega}{Z+\kappa}
\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}\left(\frac{Z_{\omega}}{\kappa}\log\left(1-\frac{x}{\omega}\right)+\frac{x(Z-2\kappa)}{\kappa\omega(\omega- x)}\right), 
  \end{split}
\end{equation}
which is 
\begin{equation}\begin{split}
\left(1-\frac{x}{\omega}\right)^{\frac{Z}{\kappa}-2}&\left[ 
 \frac{Z-\beta-\kappa}{\gamma Z} \left(\frac{2\kappa\omega}{Z+\kappa}-\frac{2\alpha_2\kappa\omega}{(Z+\kappa)^2}Z_{\omega} + \left(\alpha_1+ \frac{2\alpha_2 \kappa\omega}{Z+\kappa}
\right) \frac{x(Z-2\kappa)}{\kappa\omega(\omega- x)} \right)+ \right.\\
&\left. +\frac{Z_{\omega}}{\gamma Z}\left(\alpha_1 + \frac{2\alpha_2 \kappa\omega}{Z+\kappa}\right) \left(\frac{\beta+\kappa}{Z}+\log\left(1-\frac{x}{\omega}\right)\frac{Z-\beta-\kappa}{\kappa}\right)  \right], 
\end{split}\end{equation}
where
\begin{equation}\begin{split}
Z_{\omega}=& \frac{3 \kappa^2 ( \alpha_1 \zeta + 4 \alpha_2  \omega \zeta - 2 \alpha_1  (\kappa + \alpha_1 \omega)^2 + 
   18 \alpha_2 \kappa \omega^2 (\alpha_1 + 2 \alpha_2 \omega) + 9 \kappa \omega (\alpha_1 + 2 \alpha_2 \omega)^2)}{\zeta\, (9 \alpha_1 \kappa^2 \omega + 18 \alpha_2 \kappa^2 \omega^2 +\kappa \zeta)^{2/3}}\left( \frac{1}{ 2^{1/3}3^{2/3}} -\right. \\
    &\left.\frac{(2/3)^{1/3} \kappa ( \kappa +  \alpha_1  \omega)}{(9 \alpha_1 \kappa^2 \omega + 18 \alpha_2 \kappa^2 \omega^2 +\kappa \zeta)^{2/3}} \right) + \frac{ (2/3)^{1/3} \alpha_1 \kappa}{ (9 \alpha_1 \kappa^2 \omega + 18 \alpha_2 \kappa^2 \omega^2 +\kappa \zeta)^{1/3}}.
  \end{split}\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% beta

\bigskip

{\bf 4.} Next parameter is $\beta$ which is much simpler since $Z$ isn't function of $\beta$ so derivative is just
\begin{equation}\label{eq:db}
  \frac{d u(x)}{d\beta} =-\frac{1}{\gamma Z}\left(\alpha_1 + \frac{2\alpha_2 \kappa\omega}{Z+k}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% gamma

\bigskip

{\bf 5.} Very similar is for the $\gamma$
\begin{equation}\label{eq:dg}
  \frac{d u(x)}{d\gamma} =-\frac{Z-\beta-\kappa}{\gamma^2 Z}\left(\alpha_1 + \frac{2\alpha_2 \kappa\omega}{Z+k}\right)\left(1-\frac{x}{\omega}\right)^{Z/\kappa-2}.
\end{equation}

\section{Initial parameters stuff}
%\subsection{Initial parameter values}

Consider now the initial values of the parameters for the optimisation algorithm. At equilibrium, the following relation holds
%If we linearise the model by removing the density dependent natural mortality ($\gamma$) and consider the population at fished equilibrium, we have the following relation
\begin{equation}
  1=\int_0^\omega \frac{ \alpha_1 x + \alpha_2 x^2}{\kappa (\omega - x)} \exp\left(-\int_0^x \frac{\tilde{\beta} + f s(\lambda)}{\kappa(\omega-\lambda)}\,d\lambda\right)\,dx
\end{equation}
where $f$ is the constant fishing mortality and $\tilde{\beta}$ is a natural mortality term that is a mixture of density dependent and density independent effects. 

%But we also have
%\begin{equation}
%  1=\int_0^\omega \frac{ \alpha_1 x + \alpha_2 x^2}{\kappa (\omega - x)} \exp\left(-\int_0^x \frac{\beta + 0.4\gamma \bar{U}  + f s(\lambda)}{\kappa(\omega-\lambda)}\,d\lambda\right)\,dx
%\end{equation}

%\begin{equation}
%{{2\,\left(\int_{0}^{w}{{\frac{x^2\,e^ {- {{\int_{0}^{x}{{\frac{f s(\lambda)+\beta}{\kappa(\omega-\lambda)}}\;d\lambda}}} }}{\kappa(\omega-x)}}\;dx}
% \right)\,\left({{\int_{0}^{w}{{\frac{\left(\alpha_2 x^2+\alpha_1 x
% \right)\,e^ {- {\int_{0}^{x}{{\frac{f\,s\left(l\right)+\beta}{\kappa(\omega-
% \lambda)}}\;d\lambda}} }}{\kappa(\omega-x)}}\;dx}}}-1\right)}}
%\end{equation}

At this equilibrium, %we have the following size-structure
%\begin{equation}
%  \frac{\left(\omega-x\right)^{-1}\exp\left(-\int_0^x \frac{\tilde{\beta} + f s(\lambda)}{\kappa(\omega-\lambda)}\,d\lambda\right)}{
%\int_0^\omega \left(\omega-x\right)^{-1} \exp\left(-\int_0^x \frac{\tilde{\beta} + f s(\lambda)}{\kappa(\omega-\lambda)}\,d\lambda\right)\,dx}        
%\end{equation}
%and thus the following 
the catch structure is proportional to
\begin{equation}
  h(x)=\frac{s(x)\left(\omega-x\right)^{-1}\exp\left(-\int_0^x \frac{\tilde{\beta} + f s(\lambda)}{\kappa(\omega-\lambda)}\,d\lambda\right)}{
\int_0^\omega s(x)\left(\omega-x\right)^{-1} \exp\left(-\int_0^x \frac{\tilde{\beta} + f s(\lambda)}{\kappa(\omega-\lambda)}\,d\lambda\right)\,dx}.        
\end{equation}
If we assume the population has been roughly at equilibrium for a period of time (a visual assessment should suffice), then we can compare this theoretical catch structure to the average catch structre observed over that period. Then, given a fixed $\kappa$ and $\omega$, it is possible to estimate values for $f$ and $\tilde{\beta}$ by minimising the following objective function
\begin{equation}
  G(\theta) = \int_0^\omega l(x) \log\left(\frac{l(x)}{h(x)}\right) \,dx.
\end{equation}
where $l(x)$ is the average observed size-structure for the time period. 

This expression can be differentiated to assist with optimisation:
\begin{equation}
  \frac{d G}{d \beta} = \int_0^\omega -\frac{l(x)}{h(x)} \frac{ A(x) \left( - \int_0^x \frac{d\lambda}{\kappa(\omega-\lambda)}\right) B - A(x) \int_0^\omega A(x) \left( - \int_0^x \frac{d\lambda}{\kappa(\omega-\lambda)}\right)\,dx }{B^2}\,dx  
\end{equation}
where
\begin{equation}
  A(x) = s(x)(\omega-x)^{-1} \exp\left(-\int_0^x \frac{\tilde{\beta} + f s(\lambda)}{\kappa(\omega-\lambda)}\,d\lambda\right)
\end{equation}
and 
\begin{equation}
  B = \int_0^\omega s(x)\left(\omega-x\right)^{-1} \exp\left(-\int_0^x \frac{\tilde{\beta} + f s(\lambda)}{\kappa(\omega-\lambda)}\,d\lambda\right)\,dx
\end{equation}
and 
\begin{equation}
  \frac{d G}{d f} = \int_0^\omega -\frac{l(x)}{h(x)} \frac{ A(x) \left( - \int_0^x \frac{s(\lambda)d\lambda}{\kappa(\omega-\lambda)}\right) B - A(x) \int_0^\omega A(x) \left( - \int_0^x \frac{s(\lambda)d\lambda}{\kappa(\omega-\lambda)}\right)\,dx }{B^2}  \,dx
\end{equation}
We can simplify this further to 
\begin{equation}
  \frac{d G}{d \beta} = \int_0^\omega -l(x) \frac{ \left( - \int_0^x \frac{d\lambda}{\kappa(\omega-\lambda)}\right) B - \int_0^\omega A(x) \left( - \int_0^x \frac{d\lambda}{\kappa(\omega-\lambda)}\right)\,dx }{B}\,dx  
\end{equation}
and
\begin{equation}
  \frac{d G}{d f} = \int_0^\omega -l(x) \frac{ \left( - \int_0^x \frac{s(\lambda)d\lambda}{\kappa(\omega-\lambda)}\right) B - \int_0^\omega A(x) \left( - \int_0^x \frac{s(\lambda)d\lambda}{\kappa(\omega-\lambda)}\right)\,dx }{B}  \,dx
\end{equation}


\end{appendices}
\bibliography{spade}
\end{document}

The optimisation algorithm is essentially a BFGS (Broyden-Fletcher-Goldfarb-Shanno) method

, but treated as a bi-level optimisation where $\iota$ is solved in the inner loop. This is because $\iota$ is a `nuisance parameter', in the following senses: \emph{i}) it is not of great interest directly, \emph{ii}) it is found through a different objective function to the other parameters, and \emph{iii}) that objective function could in principle be minimised to arbitrary precision (e.g. by taking $\iota$ to be a vector of spline coefficients) without over-parameterising the objective functions of interest. Therefore we let $\tilde{\theta}$ be the \emph{non-}$\iota$ components of $\theta$, so that $\theta = \langle\tilde{\theta},\iota\rangle$. Also let the main objective function be a weighted sum of the three `interesting' objective functions: $H_*(\theta) = \xi_2 H_2(\theta) +\xi_3 H_3(\theta) + \xi_4 H_4(\theta)$. We discuss how the $\xi_i$ are chosen later.

Then we have the derivative of the main objective function, 
\begin{equation}
  \nabla H_*(\tilde{\theta};\iota) \equiv \left\langle \xi_2 \frac{d H_2}{d \alpha_1}, \xi_2 \frac{d H_2}{d \alpha_2}, \xi_2 \frac{d H_2}{d \beta}, \xi_2 \frac{d H_2}{d \gamma}, \xi_2 \frac{d H_2}{d \kappa} + \xi_3 \frac{d H_3}{d \kappa} + \xi_4 \frac{d H_4}{d \kappa}, \xi_2 \frac{d H_2}{d \omega} + \xi_3 \frac{d H_3}{d \omega} + \xi_4 \frac{d H_4}{d \omega}\right\rangle
\end{equation}

\begin{algorithm}
  \caption{Optimisation algorithm}\label{alg:opt}
  \begin{algorithmic}
    \State $B_0 \gets I$, $\tilde{\theta}_0 \gets \tilde{\theta}_\text{ini}$, $k \gets 0$
    \State $\iota \gets \argmin_\iota H_1(\iota;\tilde{\theta}_{0})$
    \While{$|| \nabla H_*(\tilde{\theta}_k;\iota) || < \epsilon$}
    \State $\mathbf{q}_k \gets - B_k \nabla H_*(\tilde{\theta}_k;\iota)$
    \State Find $\zeta_k$ that satisfies \ref{eq:w1} and \ref{eq:w2}
    \State $\mathbf{s}_k \gets \zeta_k \mathbf{q}_k$
    \State $\tilde{\theta}_{k+1} \gets \tilde{\theta}_k + \mathbf{s}_k$
    \State $\mathbf{y}_k \gets \nabla H_*(\tilde{\theta}_{k+1};\iota) - \nabla H_*(\tilde{\theta}_k;\iota)$
    \State $\rho_k \gets (\mathbf{s_k}' \mathbf{y}_k)^{-1}$
    \State $B_{k+1} \gets (I - \rho_k \mathbf{s}_k \mathbf{y}_k') B_k (I - \rho_k \mathbf{y}_k' \mathbf{s}_k) + \rho_k \mathbf{s}_k\mathbf{s}_k'$
    \State $k \gets k+1$
    \State $\iota \gets \argmin_\iota H_1(\iota;\tilde{\theta}_{k})$
    \EndWhile
%    \If{k=1}
%    \State $\zeta_k \gets 1/ || \nabla H(\theta_k)
  \end{algorithmic}
\end{algorithm}

Wolf conditions:
\begin{subequations}
  \begin{align}
    H(\theta_{k+1}) &\leq H(\theta_k) + c_1 \zeta_k \nabla H(\theta_k)' \mathbf{q}_k \label{eq:w1}\\
    \nabla H(\theta_{k+1})' &\mathbf{q}_k \geq c_2 \nabla H(\theta_k)' \mathbf{q}_k\label{eq:w2}
  \end{align}
\end{subequations}

%We discuss some of the differences between traditional matrix-based fishery models and the pde formalism.  And focus on the scale thing.
%In this article we focus on the insight this provides into scale. 
%We explore the insights this framework provides on many of the problems facing modern stock assessment, including growth plasticity.

%In a sense it is the prototypical stock assessment model - at least for species with an extended breeding period - of which all matrix-based approaches are an approximation.

%, that is to say, into a tool which can be used to inform fishery management.
%. We discuss how this framework is best suited to dealing with many of the challenges that still face stock assessment, such as plasticity, 

%Given that the final mathematical form of this model was attained more than thirty years ago, we speculate that two key technical issues have been preventing its 

%the reason for its absence from the fishery modelling literature is because of a requirement for numerical solutions. 

%Given that this kind of model has been well known in ecology for the last thirty years, we speculate that the reason for its absence from the fishery modelling literature is because of the necessetya
%\end{abstract}

%Plasticity and stock assessment:\\
%the partial differential approach}
%Mckendrick style fishery models and application to density-dependent growth ...
%Density-dependent growth effects on productivity and capacity: the case of Australian barramundi \emph{Lates calcarifer}}

\floatstyle{boxed}
\newfloat{code}{thp}{lop}
\floatname{code}{Code}
%\DeclareDelayedFloat{code}{Codes}

\floatstyle{boxed}
\newfloat{derivation}{thp}{lop}
\floatname{derivation}{Derivation}
%\DeclareDelayedFloat{derivation}{Derivations}
